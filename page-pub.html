<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
  <style>
    .navA{
      display: inline-block;
      margin-right: 13px;
      font-size: 16px;
      font-weight: 700;
      color: #000;
      text-decoration: none;
      padding: 5px ;
      border: #000 1px solid;
    }
    .navA:hover{
      color: #fff;
      background-color: #000;
    }
  </style>

  <title>Dongkuan (DK) Xu</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>



<style>
  .listbox{
      position: static;
      overflow-y: scroll;
      height: 234px;
      color: black;
      background-color: #EAF4F7;
  /*     border: 2px solid black; */
  /*     padding: 20px 50px 0px 30px; */
  /*     font-size: 15px; */
      }
</style>



<body>
  <table style="width:100%;max-width:840px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        </tbody></table>

    <br>

        <div class="navbar" style="padding-left: 18px;">
          <a href="./index.html" class="navA">About</a>
          <a href="./page-lab.html" class="navA">GIC Lab</a>
          <a href="./page-pub.html" class="navA">Publications</a>
          <a href="./page-outreach.html" class="navA">Outreach</a>
          <a href="./page-services.html" class="navA">Services</a>
          <a href="./page-talks.html" class="navA">Talks</a>
          <a href="./page-awards.html" class="navA">Awards</a>
          <a href="./page-teaching.html" class="navA">Teaching</a>
        </div>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <br />



        </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b><font color="black">Publications</font></b></heading> 

              <!-- <h3>Graduate</h3> -->
<!--               <p>
                I'm interested in computer vision, machine learning, optimization, and image processing.
                Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.
                Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2024</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/ADED.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Adaptive Draft-Verification for Efficient Large Language Model Decoding</papertitle>
              </a>
              <br>
              X. Liu, B. Lei, R. Zhang, <b>D. Xu</b> 
              <br>
              <a href="https://arxiv.org/pdf/2407.12021">PDF</a> (available) / <a href="https://anonymous.4open.science/r/ADED-C7D5">Code</a> (available)
              <p>We introduce an LLM decoding acceleration method that requires no fine-tuning. Our approach involves an adaptive draft-verification process that evolves over time to improve efficiency. We utilize a tri-gram matrixbased LLM representation to dynamically approximate the output distribution of the LLM, allowing the model to adjust to changing token probabilities during the decoding process.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/DALD.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Improving Logits-based Detector without Logits from Black-box LLMs</papertitle>
              </a>
              <br>
              C. Zeng, S. Tang, X. Yang, Y. Chen, Y. Sun, Z. Xu, Y. Li, H. Chen, W. Cheng, <b>D. Xu</b>
              <br>
              <a href="https://arxiv.org/pdf/2406.05232">PDF</a> (available) / <a>Code</a> (to appear)
              <p>We introduce a distribution-aligned method for black-box LLM detection. It aligns the surrogate model’s distribution with the unknown target LLMs. It enriches widely adopted zero-shot detection methods (DetectGPT, DNA-GPT, Fast-DetectGPT) with a ‘plug-and-play’ enhancement feature.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/ws-chatgpt.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Empowering Secondary School Teachers: Creating, Executing, and Evaluating a Transformative Professional Development Course on ChatGPT</papertitle>
              </a>
              <br>
              H. Reichert, B. Tabarsi, Z. ZHang, C. Fennell, I. Bhandari, D. Robinson, M. Drayton, C. Crofton, M. Lococo, <b>D. Xu</b>, T. Barnes
              <br>
              <a>PDF</a> (to appear) / <a>Code</a> (to appear) / <a href="https://sites.google.com/ncsu.edu/chatgpt-workshop/home"> course workshop website</a> (available)
              <p>We develop a five-session interactive course on ChatGPT's features, limitations, prompt engineering techniques, ethical considerations, and strategies for incorporating ChatGPT into teaching. Our thematic analysis highlights that after the course, teachers have a more positive & nuanced understanding of ChatGPT, with quotes with positive connotations rising from 45% to 68%.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/toolnet.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph</papertitle>
              </a>
              <br>
              X. Liu, Z. Peng, X. Yi, X. Xie, L. Xiang, Y. Liu, <b>D. Xu</b>
              <br>
              <a href="https://arxiv.org/pdf/2403.00839.pdf">PDF</a> (available) / <a>Code</a> (to appear)
              <p>We introduce ToolNet, a plug-and-play method to assists LLMs in handling massive tools. ToolNet organizes tools in a weighted directed graph (node represents tools and edges denote tool transition) based on the tool-use trajectories produced by LLMs. An LLM navigates in the graph by iteratively choosing the next one from its successors until the task is resolved. Graphs are updated online, enabling adjustment to accommodate the frequent updates of tools and new tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/AdaDiff.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>AdaDiff: Accelerating Diffusion Models through Step-Wise Adaptive Computation</papertitle>
              </a>
              <br>
              S. Tang, Y. Wang, C. Ding, Y. Liang, Y. Li, <b>D. Xu</b>
              <br>
              <em><b>[ECCV 2024]</b></em> <i>The 18th European Conference on Computer Vision</i>
              <br>
              <a href="https://arxiv.org/pdf/2309.17074">PDF</a> (available) / <a>Code</a> (to appear)
              <p>We propose an adaptive computational method that dynamically allocates computation resources in each sampling step to improve the generation efficiency of diffusion models. Our method can be seamlessly integrated into any existing diffusion models (both CNN- and Transformer-based) and can be easily combined with approaches that reduce the number of sampling steps in diffusion models.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/D-REC.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Digital Twin-Assisted Data-Driven Optimization for Reliable Edge Caching in Wireless Networks</papertitle>
              </a>
              <br>
              Z. Zhang, Y. Liu, Z. Peng, M. Chen, <b>D. Xu</b>, and S. Cui
              <br>
              <em><b>[IEEE JSAC]</b></em> <i>IEEE Journal on Selected Areas in Communications</i>
              <br>
              <b><font color="red">Impact Factor: 16.4 (as of May 2024)</font></b>
              <br>
              <a href="https://arxiv.org/pdf/2407.00286">PDF</a> (available) / <a>Code</a> (to appear)
              <p>We introduce D-REC, a DT-assisted reliable RL mechanism for wireless caching optimization. Unlike existing approaches, D-REC incorporates on-demand constraints, including state, reward, and action safety modules, to prioritize network reliability and sustainability.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/EQ-ViT.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>EQ-ViT: Algorithm-Hardware Co-Design for End-to-End Acceleration of Real-Time Vision Transformer Inference on Versal ACAP Architecture</papertitle>
              </a>
              <br>
              P. Dong, J. Zhuang, Z. Yang, S. Ji, Y. Li, <b>D. Xu</b>, H. Huang, J. Hu, A. Jones, Y. Shi, Y. Wang, P. Zhou
              <br>
              <em><b>[CODES+ISSS 2024]</b></em> <i>The International Conference on Hardware/Software Codesign and System Synthesis</i>
              <br>
              <a>PDF</a> (to appear) / <a>Code</a> (to appear)
              <p>We propose EQ-ViT, an end-to-end acceleration framework with algorithm-architecture co-design features to enable real-time ViT acceleration on AMD Versal Adaptive Compute Acceleration Platform.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/align.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models</papertitle>
              </a>
              <br>
              X. Wang, S. Duan, X. Yi, J. Yao, S. Zhou, Z. Wei, P. Zhang, <b>D. Xu</b>, M. Sun, X. Xie
              <br>
              <em><b>[IJCAI 2024]</b></em> <i>International Joint Conference on Artificial Intelligence (Survey Track)</i>
              <br>
              <a href="https://arxiv.org/pdf/2403.04204.pdf">PDF</a>
              <p>We comprehensively investigate value alignment approaches. We first unpack the historical context of alignment tracing back to the 1920s <em>(where it comes from)</em>, then delve into the mathematical essence of alignment <em>(what it is)</em>, shedding light on the inherent challenges.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/purpose.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Purpose Enhanced Reasoning through Iterative Prompting: Uncover Latent Robustness of ChatGPT on Code Comprehension</papertitle>
              </a>
              <br>
              Y. Wang, Q. Zhao, <b>D. Xu</b>, X. Liu
              <br>
              <em><b>[IJCAI 2024]</b></em> <i>International Joint Conference on Artificial Intelligence</i>
              <br>
              <a>PDF</a> (to appear) / <a>Code</a> (to appear)
              <p>We present a modular prompting framework to solve robustness issues in code comprehension for LLMs by leveraging main-purpose reasoning guidance and iterative reasoning enhancement.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/radiomap.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>RM-Gen: Conditional Diffusion Model-Based Radio Map Generation for Wireless Networks</papertitle>
              </a>
              <br>
              X. Luo, Z. Li, Z. Peng, <b>D. Xu</b>, Y. Liu
              <br>
              <em><b>[IFIP/IEEE Networking 2024]</b></em> <i>International Federation for Information Processing Networking Conference</i>
              <br>
              <a>PDF</a> (to appear) / <a>Code</a> (to appear)
              <p>We explore cost-effective radio map generation using generative diffusion probabilistic models, applicable to both indoor and outdoor wireless network scenarios, particularly valuable in complex scenarios where obtaining comprehensive measurements is challenging.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/moon.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Embracing Unknown Step by Step: Towards Reliable Sparse Training in Real World</papertitle>
              </a>
              <br>
              B. Lei, <b>D. Xu</b>, R. Zhang, B. Mallick
              <br>
              <em><b>[TMLR]</b></em> <i>Transactions on Machine Learning Research</i> 
              <br> 
              <a href="https://openreview.net/pdf?id=Db5c3Wxj9E">PDF</a> / <a href="https://github.com/StevenBoys/MOON">Code</a>
              <p>We investigate for the first time the reliability of sparse training from an out-of-distribution (OOD) perspective, which jointly considers OOD reliability and efficiency and has important implications for real-world deep neural network applications.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/PGExplainer_tpami.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Inductive and Efficient Explanations for Graph Neural Networks</papertitle>
              </a>
              <br>
              D. Luo, T. Zhao, W. Cheng, <b>D. Xu</b>, F. Han, W. Yu, X. Liu, H. Chen, X. Zhang
              <br>
              <em><b>[TPAMI]</b></em> <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>
              <br>
              <b><font color="red">Impact Factor: 23.6 (as of Feb 2024)</font></b>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10423141?casa_token=kDQSui_e8vAAAAAA:5dUBW9SMZ6F0caRar1eIF0zob68LjTyJjPt5zW0t0WWwdObdeDnnijPe-e0Y0ntKmPFcr2U5">PDF</a> / <a href="https://github.com/flyingdoog/PGExplainer">Code</a>
              <p>We present PGExplainer, a parameterized explainer for Graph Neural Networks (GNNs). PGExplainer adopts a deep neural network to parameterize the generation process of explanations and provide a global understanding of any GNN models on arbitrary machine learning tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/AGENT.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Balance is Essence: Accelerating Sparse Training via Adaptive Gradient Correction</papertitle>
              </a>
              <br>
              <U>B. Lei</U>, <b>D. Xu</b>, R. Zhang, S. He, B. K. Mallick
              <br>
              <em><b>[CPAL 2024]</b></em> <i>The 2024 Conference on Parsimony and Learning</i>
              <br>
              <b><font color="red">Oral Paper</font></b>
              <br>
              <a href="https://arxiv.org/pdf/2301.03573.pdf">PDF</a> / <a href="https://github.com/StevenBoys/AGENT">Code</a>
              <p>We propose an adaptive gradient correction method to accelerate and stabilize sparse training. Our method reduces the number of epochs up to 52.1% compared to the leading sparse training methods. Our method is compatible with both unstructured and structured sparse training pipelines.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/AutoST.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>AutoST: Training-free Neural Architecture Search for Spiking Transformers</papertitle>
              </a>
              <br>
              <U>Z. Wang</U>, Q. Zhao, J. Cui, X. Liu, <b>D. Xu</b>
              <br>
              <em><b>[ICASSP 2024]</b></em> <i>The 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing</i>
              <br>
              <a href="https://arxiv.org/pdf/2307.00293.pdf">PDF</a> / <a href="https://github.com/AlexandreWANG915/AutoST">Code</a>
              <p>We introduce AutoST, a training-free NAS method for Spiking Transformers, to rapidly identify high-performance Spiking Transformer architectures.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/llm-edu.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Students’ Perceptions and Preferences of Generative Artificial Intelligence Feedback for Programming</papertitle>
              </a>
              <br>
              <U>Z. Zhang</U>*, <U>Z. Dong</U>* (<b><font color="red">Undergrad at NC State</font></b>), Y. Shi, N. Matsuda, T. Price, <b>D. Xu</b>
              <br>
              <em><b>[AAAI/EAAI 2024]</b></em> <i>The 14th Symposium on Educational Advances in Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/pdf/2312.11567.pdf">PDF</a>
              <p>This study makes contributions to the field of <b><font color="red">computer science education</font></b>, and explores the feasibility of utilizing <b><font color="red">large language models (LLMs)</font></b> for automating feedback for Java programming assignments in an introductory computer science (CS1) class.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2023</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/ReWOO.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models</papertitle>
              </a>
              <br>
              <U>B. Xu</U>, Z. Peng, B. Lei, S. Mukherjee, Y. Liu, <b>D. Xu</b>
<!--               <br>
              <em><b>[xxx 2023]</b></em> <i>xxx xxx</i> -->
              <br>
              <a href="https://arxiv.org/abs/2305.18323"><font color="red">PDF</font></a> / <a href="https://huggingface.co/spaces/rewoo/ReWOO-Demo"><font color="red">Live Demo</font></a> / <a href="https://github.com/billxbf/ReWOO"><font color="red">Code</font></a> / <a href="https://twitter.com/billxbf/status/1663713374910251009?s=20"><font color="red">Twitter</font></a> / <a href="https://www.youtube.com/watch?v=X0Iri2lohYA"><font color="red">Auto-GPT Reading</font></a> / <a href="https://www.marktechpost.com/2023/06/04/say-goodbye-to-costly-auto-gpt-and-langchain-runs-meet-rewoo-the-game-changing-modular-paradigm-that-cuts-token-consumption-by-detaching-reasoning-from-external-observations/"><font color="red">Marktechpost Media</font></a> / <a href="https://mp.weixin.qq.com/s/giWXXjawtknZUhvBgo-NzA"><font color="red">中文解读 1</font></a> / <a href="https://zhuanlan.zhihu.com/p/635284830"><font color="red">中文解读 2</font></a>
              <p>We present a modular ALM framework to solve multi-step reasoning by decoupling reasoning from tool feedback and observations. Theoretical decomposition of prompt tokens establishes that our method substantially reduces prompting redundancy in prevailing Thought-Action-Observation ALM systems.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/Gen.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Gentopia.AI: A Collaborative Platform for Tool-Augmented LLMs</papertitle>
              </a>
              <br>
              <U>B. Xu</U>, X. Liu, H. Shen, Z. Han, Y. Li, M. Yue, Z. Peng, Y. Liu, Ziyu Yao, <b>D. Xu</b>
              <br>
              <em><b>[EMNLP 2023 (System Demo Track)]</b></em> <i>The 2023 Conference on Empirical Methods in Natural Language Processing</i>
              <br>
              <a href="https://arxiv.org/pdf/2308.04030.pdf">PDF</a> / <a href="https://github.com/Gentopia-AI/Gentopia">Web</a> / <a href="https://twitter.com/GentopiaAI">Twitter</a>
              <p>We present an augmented language model platform that enables flexible customization of agents through simple configurations, seamlessly integrating various language models, task formats, prompting modules, and plugins into a unified paradigm.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/ACC_DD.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Accelerating Dataset Distillation via Model Augmentation</papertitle>
              </a>
              <br>
              <U>L. Zhang*</U>, J. Zhang*, B. Lei, S. Mukherjee, X.Pan, B.Zhao, C. Ding, Y. Li, <b>D. Xu</b>
              <br>
              <em><b>[CVPR 2023]</b></em> <i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>
              <br>
              <b><font color="red">Highlight Paper (2.5%)</font></b>
              <br>
              <a href="https://arxiv.org/pdf/2212.06152.pdf">PDF</a> / <a href="https://github.com/ncsu-dk-lab/Acc-DD">Code</a>
              <p>We propose two model augmentation techniques, i.e. using early-stage models and weight perturbation to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20× speedup.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MuE.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>You Need Multiple Exiting: Dynamic Early Exiting for Accelerating Unified Vision Language Model</papertitle>
              </a>
              <br>
              <U>S. Tang</U>, Y. Wang, Z. Kong, T. Zhang, Y. Li, C. Ding, Y. Wang, Y. Liang, <b>D. Xu</b>
              <br>
              <em><b>[CVPR 2023]</b></em> <i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>
              <br>
              <a href="https://arxiv.org/pdf/2211.11152.pdf">PDF</a> / <a href="https://github.com/ncsu-dk-lab/MuE">Code</a>
              <p>We propose a novel early exiting strategy based on cascading input similarity with valid assumptions on saturation states in visual-language models, a pioneering exploration of extending early exiting selection to encoders and decoders of sequence-to-sequence architectures.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/CaliDD.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Rethinking Data Distillation: Do Not Overlook Calibration</papertitle>
              </a>
              <br>
              <U>D. Zhu</U>, B. Lei, J. Zhang, Y. Fang, Y. Xie, R. Zhang, <b>D. Xu</b>
              <br>
              <em><b>[ICCV 2023]</b></em> <i>International Conference on Computer Vision</i>
              <br>
              <a href="https://browse.arxiv.org/pdf/2307.12463.pdf">PDF</a>
              <p>We show that distilled data lead to not-calibratable networks due to the loss of information that is semantically meaningful but unrelated to classification tasks. We propose Masked Temperature Scaling & Distillation Training to mitigate these limitations while maintaining the efficiency.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/pFedHR.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Personalized Federated Learning via Heterogeneous Model Reassembly</papertitle>
              </a>
              <br>
              J. Wang, X. Yang, S. Cui, L. Che, L. Lyu, <b>D. Xu</b>, F. Ma
              <br>
              <em><b>[NeurIPS 2023]</b></em> <i>Thirty-seventh Conference on Neural Information Processing Systems</i>
              <br>
              <a href="https://arxiv.org/pdf/2308.08643.pdf">PDF</a>
              <p>This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. We propose pFedHR, focusing on solving the problem of heterogeneous model cooperation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/robust_prune.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models</papertitle>
              </a>
              <br>
              <U>J. Li</U>, Q. Lei, W. Cheng, <b>D. Xu</b>
              <br>
              <em><b>[EMNLP 2023]</b></em> <i>The 2023 Conference on Empirical Methods in Natural Language Processing</i>
              <br>
              <a href="https://aclanthology.org/2023.emnlp-main.79.pdf">PDF</a>
              <!-- <p>We investigate the application of robust pruning methods for language models. We propose an adaptive pruning method and place a special emphasis on replicating the embedding and feature space of dense models to preserve as much pre-trained knowledge as possible.</p> -->
              <p>We aim to answer: <b>(i)</b> What is the core to defend against adversarial attacks for sparse language models? <b>(ii)</b> How can we efficiently prevent the loss of pre-trained knowledge in pruning to preserve or even enhance robustness?
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/control_prune.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection</papertitle>
              </a>
              <br>
              <U>J. Li</U>, W. Gao, Q. Lei, <b>D. Xu</b>
              <br>
              <em><b>[EMNLP 2023 (Findings)]</b></em> <i>The 2023 Conference on Empirical Methods in Natural Language Processing</i>
              <br>
              <a href="https://aclanthology.org/2023.findings-emnlp.763.pdf">PDF</a>
              <!-- <p>We investigate the application of robust pruning methods for language models. We propose an adaptive pruning method and place a special emphasis on replicating the embedding and feature space of dense models to preserve as much pre-trained knowledge as possible.</p> -->
              <p>This paper introduces controllable randomness by generating binary masks in a specific random fashion. We aim to answer: <b>(i)</b> Which is better for pruning? a deterministic way or a randomized way? <b>(ii)</b> Can we design a consistently effective randomized pruning method?
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/co_evol.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Co-evolving Data-driven and NLU-driven Synthesizers for Generating Code in Domain Growth and Data Scarcity</papertitle>
              </a>
              <br>
              <U>J. Gu</U>, Z. Nan, Z. Peng, X. Shen, <b>D. Xu</b>
              <br>
              <em><b>[EMNLP 2023 Workshop]</b></em> <i>The 2023 Pattern-based Approaches to NLP in the Age of Deep Learning <b>(Pan-DL)</b></i>
              <br>
              <a href="https://aclanthology.org/2023.pandl-1.7.pdf">PDF</a>
              <p>We propose a circular training framework, <i>Colead</i>, which co-evolves both the data-driven synthesizer and the NLU-driven synthesizer to achieve high-quality code generation in the presence of data scarcity and domain growth.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/EffiTraff.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Toward Efficient Traffic Signal Control: Smaller Network Can Do More</papertitle>
              </a>
              <br>
              <U>S. Li</U>, H. Mei, J. Li, H. Wei, <b>D. Xu</b>
              <br>
              <em><b>[CDC 2023]</b></em> <i>The 62nd IEEE Conference on Decision and Control</i>
              <br>
              <a href="https://dongkuanx27.github.io/">PDF (to appear)</a>
              <p>We introduce EfficientLight, an RL-based traffic signal control method that balances model size and performance. In multi-intersection scenarios, our method outperforms all baseline methods with the lowest #paras and the smallest computational cost compared to other RL-based methods.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/eapp.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle><b><font color="red">E-App:</font></b> Adaptive mmWave Access Point Planning with Environmental Awareness in Wireless LANs</papertitle>
              </a>
              <br>
              Y. Liu, M. Chen, <b>D. Xu</b>, Z. Yang, S. Zhao
              <br>
              <em><b>[ICCCN 2023]</b></em> <i>The 32nd International Conference on Computer Communications and Networks</i>
              <br>
              <b><font color="red">Best Paper Award</font></b>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/10230133">PDF</a>
              <p>We develop an adaptive access point (AP) planning approach that can accurately sense the environment dynamics, reconstruct the obstacle map, and then predict the placements of mmWave APs adaptively.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/SelfPee.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Labels Are Not Necessary: Assessing Peer-Review Helpfulness Using Domain Adaptation Based on Self-Training</font></papertitle>
              </a>
              <br>
              <U>C. Liu</U>, D. Doshi, M. Bhargava, R. Shang, J. Cui, <b>D. Xu</b>, E. Gehringer
              <br>
              <em><b>[BEA 2023]</b></em> <i>The 18th Workshop on Innovative Use of NLP for Building Educational Applications</i>
              <br>
              <a href="https://aclanthology.org/2023.bea-1.15.pdf">PDF</a>
              <p>This study highlights the pedagogical significance of predicting useful comments in mutual assessment to promote student learning and reduces the need to collect labeled data via domain adaptation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/CaliRare.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Towards Reliable Rare Category Analysis on Graphs via Individual Calibration</papertitle>
              </a>
              <br>
              L. Wu, B. Lei, <b>D. Xu</b>, D. Zhou
              <br>
              <em><b>[KDD 2023]</b></em> <i>The 29th SIGKDD Conference on Knowledge Discovery and Data Mining</i>
              <br>
              <!-- <a href="https://arxiv.org/pdf/2211.07886.pdf">PDF</a> -->
              <p>How can we quantify the uncertainty in the learning process and enable reliable rare category analysis? We jointly learn the characterizations of rare categories and calibrate the confidence.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/ODQA.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>A Survey for Efficient Open Domain Question Answering</papertitle>
              </a>
              <br>
              Q. Zhang, S. Chen, <b>D. Xu</b>, Q. Cao, X, Chen, T. Cohn, M. Fang
              <br>
              <em><b>[ACL 2023]</b></em> <i>The 61th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://arxiv.org/pdf/2211.07886.pdf">PDF</a>
              <p>We walk through the ODQA models and conclude the core techniques on efficiency. Quantitative analysis on memory cost, processing speed, accuracy and overall comparison are given.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/CigL.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Calibrating the Rigged Lottery: Making All Tickets Reliable</papertitle>
              </a>
              <br>
              <U>B. Lei</U>, R. Zhang, <b>D. Xu</b>, B. K. Mallick
              <br>
              <em><b>[ICLR 2023]</b></em> <i>The 11th International Conference on Learning Representations</i>
              <br>
              <a href="https://arxiv.org/pdf/2302.09369.pdf">PDF</a>
              <p> We for the first time identify and study the reliability problem of sparse training and find that sparse training exacerbates the over-confidence problem of DNNs. We then develop a new sparse training method, CigL, to produce more reliable sparse models.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/edugpt.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Exploring the Augmented Large Language Model with Mathematical tools in Personalized and Efficient Education</papertitle>
              </a>
              <br>
              <U><a href="https://zihandong.wordpress.ncsu.edu/">Zihan Dong</a></U> (<b><font color="red">Undergrad at NC State</font></b>), <b>D. Xu</b>
              <br>
              <em><b>[ICAIBD 2023]</b></em> <i>The 6th International Conference on Artificial Intelligence and Big Data</i>
              <p>This study explores how ChatGPT personalizes the learning experience, how it can be augmented with math and physical performance, and how educators can ensure that the LLM algorithm is unbiased.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/DSTEE.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Dynamic Sparse Training via Balancing the Exploration-Exploitation Trade-off</papertitle>
              </a>
              <br>
              <U>S. Huang</U>, B. Lei, <b>D. Xu</b>, H. Peng, Y. Sun, M. Xie, C. Ding
              <br>
              <em><b>[DAC 2023]</b></em> <i>The 60th Design Automation Conference</i>
              <br>
              <a href="https://arxiv.org/pdf/2211.16667.pdf">PDF</a>
              <p>To assist explainable sparse training, we propose important weights exploitation and weights coverage exploration to characterize sparse training. Our method does not need to train dense models, achieving up to 95% sparsity ratio and even higher accuracy than dense training, with same amount of iterations.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/NDSNN.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Neurogenesis Dynamics-inspired Spiking Neural Network Training Acceleration</papertitle>
              </a>
              <br>
              <U>S. Huang</U>, H. Fang, K. Mahmood, B. Lei, N. Xu, B. Lei, Y. Sun, <b>D. Xu</b>, W. Wen, C. Ding
              <br>
              <em><b>[DAC 2023]</b></em> <i>The 60th Design Automation Conference</i>
              <br>
              <p> We propose an energy efficient spiking neural network training workflow, and design a new drop-andgrow strategy with decreasing number of non-zero weights in the process of dynamically updating sparse mask. We demonstrate extremely high sparsity (i.e., 99%) model performance in SNN based vision tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MANA.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Efficient Informed Proposals for Discrete Distributions via Newton’s Series Approximation</papertitle>
              </a>
              <br>
              <U>Y. Xiang*</U>, <U>D. Zhu*</U>, B. Lei, <b>D. Xu</b>, R. Zhang
              <br>
              <em><b>[AISTATS 2023]</b></em> <i>The 26th International Conference on Artificial Intelligence and Statistics</i>
              <br>
              <a href="http://www.personal.psu.edu/dux19/">PDF</a>
              <p> We develop a gradient-like proposal for any discrete distribution without this strong requirement. Built upon a locally-balanced proposal, our method efficiently approximates the discrete likelihood ratio via a Newton’s series expansion to enable a large and efficient exploration in discrete spaces.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/DisVar.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Improving Long-tailed Classification by Disentangled Variance Transfer</papertitle>
              </a>
              <br>
              Y. Tian, W. Gao, Q. Zhang, P. Sun, <b>D. Xu</b>
              <br>
              <em><b><i>Internet of Things</i></b></em> 
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S2542660523000100">PDF</a>
              <p>We propose a class-based covariance transfer method from the perspective of disentangling to transfer covariance information in long-tailed classification task.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/Auto-CAM.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Auto-CAM: Label-Free Earth Observation Imagery Composition and Masking Using Spatio-Temporal Dynamics</papertitle>
              </a>
              <br>
              Y. Xie, Z. Li, H. Bao, X. Jia, <b>D. Xu</b>, X. Zhou, S. Skakun
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The 37th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26704">PDF</a>
              <p>We propose an autonomous image composition and masking method for <b>cloud masking</b>, a fundamental task in Earth observation problems across social sectors such as <b>agriculture, energy, and water</b>.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/InfoTS.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Time Series Contrastive Learning with Information-Aware Augmentations</papertitle>
              </a>
              <br>
              D. Luo, W. Cheng, Y. Wang, <b>D. Xu</b>, J. Ni, W. Yu, X. Zhang, Y. Liu, Y. Chen, H. Chen, X. Zhang
              <br>
              <em><b>[AAAI 2023]</b></em> <i>The 37th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25575">PDF</a>
              <p>We propose an adaptive data augmentation method to avoid ad-hoc choices or painstakingly trial-and-error tuning for time series representation learning.</p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2022</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/AutoDistil.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="http://www.personal.psu.edu/dux19/" id="3DSP"> -->
              <a id="3DSP">
                <papertitle><font color="red"> AutoDistil:</font> Few-shot Task-agnostic Neural Architecture Search for Distilling Large Language Models </papertitle>
              </a>
              <br>
              <b>D. Xu</b>, S. Mukherjee, X. Liu, D. Dey, W. Wang, X. Zhang, A. H. Awadallah, J. Gao
              <br>
              <em><b>[NeurIPS 2022]</b></em> <i>The 36th Conference on Neural Information Processing Systems</i>
              <br>
              <a href="https://arxiv.org/pdf/2201.12507.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a>
              <p>We develop a few-shot task-agnostic NAS framework, AutoDistil, for distilling large language models into compressed students with variable computational cost. <b>AutoDistil outperforms leading baselines with upto 3x additional reduction in computational cost and negligible loss in task performance.</b></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/s4.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="http://www.personal.psu.edu/dux19/" id="3DSP"> -->
              <a id="3DSP">
                <papertitle><font color="red"> S4:</font> a High-sparsity, High-performance AI Accelerator</papertitle>
              </a>
              <br>
              I. E. Yen, Z. Xiao, <b>D. Xu</b>
              <br>
              <em><b>[SNN 2022]</b></em> <i>Sparsity in Neural Networks 2022 Workshop</i>
              <br>
              <a href="https://arxiv.org/pdf/2207.08006.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We introduce the first commercial hardware platform supporting high-degree sparsity acceleration up to 32 times — S4. S4 provides a (sparse) equivalent computation power of 944 TOPS in INT8 and 472 TFLOPS in BF16, and has 20GB LPDDR4 memory with up to 72 GB memory bandwidth in a low 70 Watt power envelope. We demonstrate several-times practical inference speedup on S4 over mainstream inference platforms such as <b>Nvidia T4</b>.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/AE-BERT.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="http://www.personal.psu.edu/dux19/" id="3DSP"> -->
              <a id="3DSP">
                <papertitle>An Automatic and Efficient BERT Pruning for <font color="red">Edge AI Systems</font></papertitle>
              </a>
              <br>
              S. Huang, N. Liu, Y. Liang, H. Peng, H. Li, <b>D. Xu</b>, M. Xie, C. Ding
              <br>
              <em><b>[ISQED 2022]</b></em> <i>The 23rd IEEE International Society for Quality Electronic Design</i>
              <br>
              <a href="https://www.youtube.com/watch?v=3BD8BGe4-Go">Video</a> / <a href="http://www.personal.psu.edu/dux19/">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We propose AE-BERT, an automatic and efficient pruning framework. AE-BERT achieves the inference time of a single BERT-BASE encoder on <b>Xilinx Alveo U200 FPGA board that is 1.83x faster compared to Intel(R) Xeon(R) Gold 5218 (2.30GHz) CPU.</b></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/SPD.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="http://www.personal.psu.edu/dux19/" id="3DSP"> -->
              <a id="3DSP">
                <papertitle>Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm</papertitle>
              </a>
              <br>
              S. Huang*, <b>D. Xu*</b>, I. E. Yen, S. Chang, B. Li, C. Ding, et al.
              <br>
              <em><b>[ACL 2022]</b></em> <i>The 60th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://arxiv.org/pdf/2110.08190.pdf">PDF</a> / <a href="https://github.com/shaoyiHusky/SparseProgressiveDistillation">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We study <b>network pruning of Transformer-based language models</b> under the pre-training and fine-tuning paradigm and propose a <b>counter-traditional hypothesis</b> that pruning increases the risk of overfitting when performed during the fine-tuning phase.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2021</h2>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/InfoGCL.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle> InfoGCL: Information-Aware Graph Contrastive Learning </papertitle>
              </a>
              <br>
              <b>D. Xu</b>, W. Cheng, D. Luo, H. Chen, X. Zhang
              <br>
              <em><b>[NeurIPS 2021]</b></em> <i>The 35th Conference on Neural Information Processing Systems</i>
              <br>
              <a href="https://proceedings.neurips.cc/paper/2021/file/ff1e68e74c6b16a1a7b5d958b95e120c-Paper.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p><b>We propose an information-aware contrastive learning framework for graph-structure data, and show for the first time that all recent graph contrastive learning methods can be unified by our framework.</b></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/SparseBERT.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>(SparseBERT) Rethinking Network Pruning - under the Pre-train and Fine-tune Paradigm</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Ian En-Hsu Yen, Jinxi Zhao, Zhibin Xiao
              <br>
              <em><b>[NAACL-HLT 2021]</b></em> <i>2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics</i>
              <br>
              <a href="https://arxiv.org/pdf/2104.08682.pdf">PDF</a> / <a href="https://github.com/DerronXu/SparseBERT">Code</a> / <a href="https://github.com/DerronXu/SparseBERT">Supp</a> / <a href="https://github.com/DerronXu/SparseBERT/blob/main/NAACL21%20-%20Slides%20-%20V1.pdf">Slides</a>
              <p><b>We study how knowledge is transferred and lost during the pre-train, fine-tune, and pruning process, and propose a knowledge-aware sparse pruning process that achieves significantly superior results than existing literature.</b></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/CrossLingual.png" alt="3DSP" width="160" height="140" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Data Augmentation with Adversarial Training for Cross-Lingual NLI</papertitle>
              </a>
              <br>
              Xin Dong, Yaxin Zhu, Zuohui Fu, <b>Dongkuan Xu</b>, Gerard de Melo
              <br>
              <em><b>[ACL 2021]</b></em> <i>The 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</i>
              <br>
              <a href="https://aclanthology.org/2021.acl-long.401.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We study data augmentation for cross-lingual natural language inference and propose two methods of training a generative model to induce synthesized examples to reflect more diversity in a semantically faithful way.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MCDA.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Deep Multi-Instance Contrastive Learning with Dual Attention for Anomaly Precursor Detection</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Cheng, Jingchao Ni, Dongsheng Luo, Masanao Natsumeda, Dongjin Song, Bo Zong, Haifeng Chen, Xiang Zhang
              <br>
              <em><b>[SDM 2021]</b></em> <i>The 21th SIAM International Conference on Data Mining </i>
              <br>
              <a href="https://github.com/DerronXu/MCDA/blob/main/SDM2021_MCDA.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="https://github.com/DerronXu/MCDA/blob/main/SDM2021_MCDA_Supp.pdf">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We utilize multi-instance learning to model the uncertainty of precursor period, and design a contrastive loss to address the issue that annotated anomalies are few.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MT-RMN.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Multi-Task Recurrent Modular Networks</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Cheng, Xin Dong, Bo Zong, Wenchao Yu, Jingchao Ni, Dongjin Song, Xuchao Zhang, Haifeng Chen, Xiang Zhang
              <br>
              <em><b>[AAAI 2021]</b></em> <i>The 35th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://github.com/DerronXu/MT-RMN/blob/main/4139.XuD.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="https://github.com/DerronXu/MT-RMN/blob/main/AAAAI2021_ID4139_Slides.pdf">Slides</a>
              <p>We propose MT-RMN to dynamically learn task relationships and accordingly learn to assemble composable modules into complex layouts to jointly solve multiple sequence processing tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/TRRN.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Transformer-Style Relational Reasoning with Dynamic Memory Updating for Temporal Network Modeling</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Junjie Liang, Wei Cheng, Hua Wei, Haifeng Chen, Xiang Zhang
              <br>
              <em><b>[AAAI 2021]</b></em> <i>The 35th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://github.com/DerronXu/TRRN/blob/main/4093.XuD.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="https://github.com/DerronXu/TRRN/blob/main/AAAAI2021_ID4093_Slides.pdf">Slides</a>
              <p>We propose TRRN to model temporal networks by employing transformer-style self-attention to reason over a set of memories.</p> <!--  and Gumbel-softmax reparameterization. -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MoveSD.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>How Do We Move: Modeling Human Movement with System Dynamics</papertitle>
              </a>
              <br>
              Hua Wei, <b>Dongkuan Xu</b>, Junjie Liang, Zhenhui Li
              <br>
              <em><b>[AAAI 2021]</b></em> <i>The 35th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/pdf/2003.00613.pdf">PDF</a> / <a href="http://www.personal.psu.edu/dux19/">Code</a> / <a href="http://www.personal.psu.edu/dux19/">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We propose MoveSD to model state transition in human movement from a novel perspective, by learning the decision model and integrating the system dynamics.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/L-DKGPR.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Longitudinal Deep Kernel Gaussian Process Regression</papertitle>
              </a>
              <br>
              Junjie Liang, Yanting Wu, <b>Dongkuan Xu</b>, Vasant Honavar
              <br>
              <em><b>[AAAI 2021]</b></em> <i>The 35th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/pdf/2005.11770.pdf">PDF</a> / <a href="https://github.com/junjieliang672/L-DKGPR">Code</a> / <a href="https://github.com/junjieliang672/L-DKGPR/blob/master/Appendix_LDKGPR.pdf">Supp</a> / <a href="http://www.personal.psu.edu/dux19/">Slides</a>
              <p>We introduce Longitudinal deep kernel Gaussian process regression to fully automate the discovery of complex multi level correlation structure from longitudinal data.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2020</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/PGExplainer.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Parameterized Explainer for Graph Neural Network</papertitle>
              </a>
              <br>
              Dongsheng Luo, Wei Cheng, <b>Dongkuan Xu</b>, Wenchao Yu, Bo Zong, Haifeng Chen, Xiang Zhang
              <br>
              <em><b>[NeurIPS 2020]</b></em> <i>The 34th Conference on Neural Information Processing Systems</i>
              <br>
              <a href="https://arxiv.org/pdf/2011.04573.pdf">PDF</a> / <a href="https://github.com/flyingdoog/PGExplainer">Code</a> / <a href="https://arxiv.org/pdf/2011.04573.pdf">Supp</a> / <a href="https://github.com/flyingdoog/PGExplainer">Slides</a>
              <p>We propose to adopt deep neural networks to parameterize the generation process of explanations, which enables a natural approach to multi-instance explanations.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/cross-lingual.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Leveraging Adversarial Training in Self-Learning for Cross-Lingual Text Classification</papertitle>
              </a>
              <br>
              Xin Dong, Yaxin Zhu, Yupeng Zhang, Zuohui Fu, <b>Dongkuan Xu</b>, Sen Yang, Gerard de Melo
              <br>
              <em><b>[SIGIR 2020]</b></em> <i>The 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</i>
              <br>
              <a href="https://arxiv.org/pdf/2007.15072.pdf">PDF</a> / <a href="https://github.com/Moonet/CLTC_SL">Code</a> / <a href="https://github.com/Moonet/CLTC_SL">Supp</a> / <a href="https://github.com/Moonet/CLTC_SL">Slides</a>
              <p>We propose a semi-supervised adversarial perturbation framework that encourages the model to be more robust towards such divergence and better adapt to the target language.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/deeptrend.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Tensorized LSTM with Adaptive Shared Memory for Learning Trends in Multivariate Time Series</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Cheng, Bo Zong, Dongjin Song, Jingchao Ni, Wenchao Yu, Yanchi Liu, Haifeng Chen, Xiang Zhang
              <br>
              <em><b>[AAAI 2020]</b></em> <i>The 34th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://github.com/DerronXu/DeepTrends/blob/master/AAAI20_DeepTrends.pdf">PDF</a> / <a href="https://github.com/DerronXu/DeepTrends">Code</a> / <a href="https://github.com/DerronXu/DeepTrends/blob/master/Poster_DeepTrends.pdf">Poster</a> / <a href="https://github.com/DerronXu/DeepTrends/blob/master/AAAI2020-slides-DongkuanXu.pdf">Slides</a>
              <p>We propose a deep architecture for learning trends in multivariate time series, which jointly learns both local and global contextual features for predicting the trend of time series.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/LMLFM.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Longitudinal Multi-Level Factorization Machines</papertitle>
              </a>
              <br>
              Junjie Liang, <b>Dongkuan Xu</b>, Yiwei Sun, Vasant Honavar
              <br>
              <em><b>[AAAI 2020]</b></em> <i>The 34th AAAI International Conference on Artificial Intelligence</i>
              <br>
              <a href="https://arxiv.org/abs/1911.04062">PDF</a> / <a href="https://github.com/junjieliang672/LMLFM">Code</a> / <a href="https://github.com/junjieliang672/LMLFM/blob/master/LMLFM_AAAI_2020_supp.pdf">Supp</a>
              <p>We propose longitudinal kulti-level factorization machine, to the best of our knowledge, the first model to address these challenges in learning predictive models from longitudinal data.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2019</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/AdaNN.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Adaptive Neural Network for Node Classification in Dynamic Networks</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Cheng, Dongsheng Luo, Yameng Gu, Xiao Liu, Jingchao Ni, Bo Zong, Haifeng Chen, Xiang Zhang
              <br>
              <em><b>[ICDM 2019]</b></em> <i>The 19th IEEE International Conference on Data Mining </i>
              <br>
              <a href="https://github.com/DerronXu/AdaNN/blob/master/ICDM19_AdaNN.pdf">PDF</a> / <a href="https://github.com/DerronXu/AdaNN/blob/master/ICDM19_AdaNN_Slides.pdf">Slides</a>
              <p>We propose an adaptive neural network for node classification in dynamic networks, which is able to consider the evolution of both node attributes and network topology.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/STAR.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Spatio-Temporal Attentive RNN for Node Classification in Temporal Attributed Graphs</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Cheng, Dongsheng Luo, Xiao Liu, Xiang Zhang
              <br>
              <em><b>[IJCAI 2019]</b></em> <i>The 29th International Joint Conference on Artificial Intelligence </i>
              <br>
              <a href="https://github.com/DerronXu/STAR/blob/master/IJCAI2019_STAR_CameraReady.pdf">PDF</a> / <a href="https://github.com/DerronXu/STAR">Code</a> / <a href="https://github.com/DerronXu/STAR/blob/master/Poster_IJCAI19.pdf">Poster</a> / <a href="https://github.com/DerronXu/STAR/blob/master/Slides_STAR.pdf">Slides</a>
              <p>We propose a spatio-temporal attentive RNN model, which aims to learn node representations for classification by jointly considering both the temporal and spatial patterns of the node.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/DeepCC.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Deep Co-Clustering</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Cheng, Dongsheng Luo, Xiao Liu, Xiang Zhang
              <br>
              <em><b>[SDM 2019]</b></em> <i>The 19th SIAM International Conference on Data Mining </i>
              <br>
              <a href="https://github.com/DerronXu/Deep-Co-Clustering/blob/master/SDM2019_DeepCC.pdf">PDF</a> / <a href="https://github.com/DerronXu/Deep-Co-Clustering">Code</a> / <a href="https://github.com/DerronXu/Deep-Co-Clustering/blob/master/SDM2019_DeepCC_Supplemental_Materials.pdf">Supp</a> / <a href="https://github.com/DerronXu/Deep-Co-Clustering/blob/master/Poster-SDM19-DK-2.pdf">Poster</a> / <a href="https://github.com/DerronXu/Deep-Co-Clustering/blob/master/SDM19-DCC-Slides.pdf">Slides</a>
              <p>DeepCC utilizes the deep autoencoder for dimension reduction, and employs a variant of Gaussian mixture model to infer the cluster assignments. A mutual information loss is proposed to bridge the training of instances and features.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2018</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/DMNE.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Co-Regularized Deep Multi-Network Embedding</papertitle>
              </a>
              <br>
              Jingchao Ni, Shiyu Chang, Xiao Liu, Wei Cheng, Haifeng Chen, <b>Dongkuan Xu</b> and Xiang Zhang
              <br>
              <em><b>[WWW 2018]</b></em> <i>The 27th International Conference on World Wide Web </i>
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3178876.3186113">PDF</a> / <a href="https://github.com/nijingchao/dmne">Code</a>
              <p>DMNE coordinates multiple neural networks (one for each input network data) with a co-regularized loss function to manipulate cross-network relationships, which can be many-to-many, weighted and incomplete.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MILPIG.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="http://www.personal.psu.edu/dux19/" id="3DSP">
                <papertitle>Multiple Instance Learning Based on Positive Instance Graph</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Wei Zhang, Jia Wu, Yingjie Tian, Qin Zhang, Xindong Wu
              <br>
              <i>arXiv preprint </i>
              <br>
              <p>Most multi-instance learning (MIL) methods that study true positive instances ignore 1) the global similarity among positive instances and 2) that negative instances are non-i.i.d.. We propose a MTL method based on positive instance graph updating to address this issue.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/review_mil.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>A Review of Multi-Instance Learning Research</papertitle>
              </a>
              <br>
              Yingjie Tian, <b>Dongkuan Xu</b>, Chunhua Zhang
              <br>
              <i><em><b>Operations Research Transactions</b></em>, 2018</i>
              <br>
              <a href="https://www.cnki.com.cn/Article/CJFDTotal-YCXX201802003.htm">PDF</a>
              <p>This paper reviews the research progress of multi-instance learning (MTL), introduces different assumptions, and categories MTL methods into instance-level, bag-level, and embedded-space. Extensions and major applications in various areas are discussed at last.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2017</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/SALE.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>SALE: Self-Adaptive LSH Encoding for Multi-Instance Learning</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Jia Wu, Dewei Li, Yingjie Tian, Xingquan Zhu, Xindong Wu
              <br>
              <i><em><b>Pattern Recognition</b></em>, 2017</i>
              <br>
              <a href="http://www.sciencedirect.com/science/article/pii/S0031320317301802">PDF</a>
              <p>We propose a self-adaptive locality-sensitive hashing encoding method for multi-instance learning (MIL), which efficiently deals with large MIL problems.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/metric.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>Metric Learning for Multi-Instance Classification with Collapsed Bags</papertitle>
              </a>
              <br>
              Dewei Li, <b>Dongkuan Xu</b>, Jingjing Tang, Yingjie Tian
              <br>
              <em><b>[IJCNN 2017]</b></em> <i>The 30th IEEE International Joint Conference on Neural Networks </i>
              <br>
              <a href="http://ieeexplore.ieee.org/abstract/document/7965878/">PDF</a>
              <p>We propose a metric learning method for multi-instance classification, aiming to find an instance-dependent metric by maximizing the relative distance on neighborhood level.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2016</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/PIGMIL.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>PIGMIL: Positive Instance Detection via Graph Updating for Multiple Instance Learning</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Jia Wu, Wei Zhang, Yingjie Tian
              <br>
              <i>arXiv preprint arXiv:1612.03550, 2016</i>
              <br>
              <a href="https://arxiv.org/pdf/1612.03550.pdf">PDF</a>
              <p>We propose a positive instance detection method based on multiple instance learning, of which the core idea is that true positive instances should not only be similar to themselves globally but also different from negative instances robustly.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/MMCM.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle> Multi-Metrics Classification Machine</papertitle>
              </a>
              <br>
              Dewei Li, Wei Zhang, <b>Dongkuan Xu</b>, Yingjie Tian
              <br>
              <em><b>[ITQM 2016]</b></em> <i>The 4th International Conference on Information Technology and Quantitative Management </i>
              <br>
              <a href="https://www.researchgate.net/profile/Dewei_Li4/publication/305952736_Multi-metrics_Classification_Machine/links/584e033308aed95c25032db3/Multi-metrics-Classification-Machine.pdf">PDF</a>
              <b><font color="red">(Best Paper Award)</font></b>
              <p>We propose a metric learning approach called multi-metrics classification machine. We establish an optimization problem for each class (each metric) to learn multiple metrics independently.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <h2><b><font color="red">2021</font></b></h2> -->
              <h2>2015</h2>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/clustering.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>A Comprehensive Survey of Clustering Algorithms</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Yingjie Tian
              <br>
              <i><em><b>Annals of Data Science</b></em>, 2015</i>
              <br>
              <a href="https://link.springer.com/content/pdf/10.1007%2Fs40745-015-0040-1.pdf">PDF</a>
              <!-- <b><font color="red">(1100 citations)</font></b> -->
              <p>We introduce the definition of clustering, the basic elements involved in clustering process, and categorize the clustering algorithms into the traditional ones and the modern ones. All the algorithms are discussed comprehensively.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h3>Undergraduate</h3>
 <!--              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing.
                Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.
                Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/STEPMRS.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>A Support Vector Machine-based Ensemble Prediction for Crude Oil Price with VECM and STEPMRS</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Tianjia Chen, Wei Xu
              <br>
              <i><em><b>International Journal of Global Energy Issues</b></em>, 2015</i>
              <br>
              <a href="http://www.inderscienceonline.com/doi/abs/10.1504/IJGEI.2015.069488">PDF</a>
              <p>This paper proposes a support vector machine-based ensemble model to forecast crude oil price based on VECM and stochastic time effective pattern modelling and recognition system (STEPMRS).</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DK/ECM.png" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a id="3DSP">
                <papertitle>A Neural Network-Based Ensemble Prediction Using PMRS and ECM</papertitle>
              </a>
              <br>
              <b>Dongkuan Xu</b>, Yi Zhang, Cheng Cheng, Wei Xu, Likuan Zhang
              <br>
              <em><b>[HICSS 2014]</b></em> <i>The 47th Hawaii International Conference on System Science </i>
              <br>
              <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758769">PDF</a>
              <p>This paper presents an integrated model to forecast crude oil prices, where pattern modelling & recognition system is used to model the price trend and error correction model is offered to forecast errors. A neural network layer is employed to integrate the results.</p>
            </td>
          </tr>

		</tbody></table>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:0px">
              <br><hr width=80%>
              <p style="text-align:right;font-size:small;">
                *Last updated on 07/28/2024*
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
